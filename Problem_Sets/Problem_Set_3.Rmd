---
title: 'GSE 520: Problem Set #3'
author: 
  - "Rus Adamovics-Davtian"
  - "Student Name 2 (delete if only one student or add more if more than two)"
output: html_document
---

### Question 1

Airlines routinely sell more tickets than there are seats available on their airplanes.  When more people show up than there are seats on the plane, the airline has to offer the excess passengers vouchers to take another flight.  Let $q$ denote the quantity of tickets oversold for a flight, i.e. tickets sold minus capacity.  Let $v$ denote the number of vouchers that must be offered for a particular flight.  Assume that $E(v | q) = q/2$, which is the expected number of vouchers they will have to offer if they oversell the flight by $q$.  On a typical day, the airline operates 43.75% flights sold at capacity, 31.25% flights oversold by (1), 18.75% flights oversold by (2), and 6.25% flights oversold by (3).

Use the law of iterated expectations to find $E(v)$, which is the expected number of vouchers the airline will have to offer *for a typical flight* on a typical day. (Hint: the law of iterated expectations say $E(v) = E_{q} [ E (v | q)]$

>**Solution:** 
\begin{align*}
E(v) = & E_{q} [ E (v | q)] = \sum_{q=0}^{3} E[v | q = q] * Pr(q = q)\\
E(v) = & ((0/2)*0.4375) + ((1/2)*0.3125) + ((2/2)*0.1875) + ((3/2)*0.0625)\\
E(v) = & 0.4375
\end{align*}

### Question 2

The data set in CEOSAL2 contains salary information on chief executive officers for U.S. corporations.   In addition to salary the data contain other information on the CEO and the CEO's company.  For example, CEO tenure, firm sales, firm market value, etc.  Consider predicting CEO $salary$ ($y$) with a single variable $x$ in the dataset using the prediction function $\hat{y} = a + b x$.  Your objective is to choose the variable $x$ that you think explains as much of the variation in $salary$ as possible.  

a. What variable did you choose for $x$?

>**Solution:**  
```{r}
options(scipen=999)
ceo <- load("C:/Users/rusla/OneDrive/GSE_520/R Data/ceosal2.RData")
round(sort(cor(data)[,1], decreasing = T),3)
```

> Based on calculating the correlation $(R)$ value between the response variable and all other variables, I choose lmktval (log of market value) as the variable that explains as much of the variation in salary as possible since it is the independent variable with the largest linear correlation to salary.

b. Using ```R``` and the formulas we derived in class, predict $y$ with $x$.  How much of the variation in $salary$ are you able to explain with $x$?  Report your calculation of $a$, $b$, the $SST$, the $SSE$, and the $R^2$.

>**Solution:**
```{r}
b <- cov(data$salary, data$lmktval) / var(data$lmktval)
a <- mean(data$salary) - b*mean(data$lmktval)
y_hat <- a + b*(data$lmktval)
SST <- sum((data$salary - mean(y_hat))^2)
SSE <- sum((data$salary - y_hat)^2)
R_2 <- 1 - (SSE / SST)
cat(' a: ', round(a, 3),'\n',
    'b: ', round(b, 3), '\n',
    'SSE: ', SSE, '\n',
    'SST: ', SST, '\n',
    'R^2: ', round(R_2, 3))
```


c. Instead, define $y=\ln(salary)$ and using the same formulas, predict $y$ with $x$.  In what sense are you better able to predict $salary$?
  
>**Solution:** 
```{r}
round(sort(cor(data)[,10], decreasing = T),3)
library(ggplot2)
library(tidyr)
df <- data %>% dplyr::select(salary, lsalary) %>% 
  gather(key = type, value = value) 
ggplot(data = df, aes(x = value)) + geom_histogram() + facet_wrap(~type, scales ="free")
b <- cov(data$lsalary, data$lmktval) / var(data$lmktval)
a <- mean(data$lsalary) - b*mean(data$lmktval)
y_hat <- a + b*(data$lmktval)
SST <- sum((data$lsalary - mean(y_hat))^2)
SSE <- sum((data$lsalary - y_hat)^2)
R_2 <- 1 - (SSE / SST)
cat(' a: ', round(a, 3),'\n',
    'b: ', round(b, 3), '\n',
    'SSE: ', SSE, '\n',
    'SST: ', SST, '\n',
    'R^2: ', round(R_2, 3))
```

> As seen above, performing a natural log transformation on salary changes the distribution of the data from right skewed to a distribution closer to normal. This transformation allows for higher magnitudes of linear correlations among other predictors which is reflected in the correlation matrix. Since the predictor variables are more linearly correlated with log salary as opposed to salary, we are better able to predict salary from the transformation model than the non-transformation model (Shown from the same predictor getting a larger R^2 than before).     

### Question 3

Using the same data set as Question 2, next consider predicting $\ln(salary)$, using the linear prediction function $\ln(salary) = a + b x$, except now $x$ does not have to be a single variable in the data set.  Create $x$ as a composite function of the variables in the data, for example you might have $x = .1 age -.05 ceoten$.  You can make any crazy function for $x$ to use in your prediction function to try and get the highest R-squared you possibly can.  (You might not get a full score for this question if other students do substantially better than your group)

a. What variable did you choose for $x$?

>**Solution:**  
```{r}
cov_matrix_X <- cov(data[, c("lsales","lmktval","profmarg","comtensq","ceoten")])
cov_X_y <- cov(data[, c("lsales","lmktval","profmarg","comtensq","ceoten")],
data$lsalary)
b1 <- solve(cov_matrix_X, cov_X_y)[1]
b2 <- solve(cov_matrix_X, cov_X_y)[2]
b3 <- solve(cov_matrix_X, cov_X_y)[3]
b4 <- solve(cov_matrix_X, cov_X_y)[4]
b5 <- solve(cov_matrix_X, cov_X_y)[5]
b0 <- mean(data$lsalary) - b1*mean(data$lsales) - b2*mean(data$lmktval) - b3*mean(data$profmarg) - b4*mean(data$comtensq) - b5*mean(data$ceoten)
y_hat <- b0 + b1*(data$lsales) + b2*(data$lmktval) + b3*(data$profmarg) + b4*(data$comtensq) + b5*(data$ceoten)
SST <- sum((data$lsalary - mean(y_hat))^2)
SSE <- sum((data$lsalary - y_hat)^2)
R_2 <- 1 - (SSE / SST)
cat(' b0: ', round(b0, 3),'\n',
    'b1: ', round(b1, 3), '\n',
    'b2: ', round(b2, 3), '\n',
    'b3: ', round(b3, 3), '\n',
    'b4: ', round(b4, 5), '\n',
    'b5: ', round(b5, 3), '\n',
    'SSE: ', SSE, '\n',
    'SST: ', SST, '\n',
    'R^2: ', round(R_2, 3))
```


b. What is the model fit you were able to achieve with the variable you created. How does your model fit compare to your answer in Question 2, Part C above?

>**Solution:**  


### Question 4

a. Consider the prediction function $\hat{y}_i = a$.  Given a sample $y = \{y_1,y_2,\ldots,y_n\}$, show how to use this data to find the value of $a$ that minimizes the prediction error (i.e., what value of $a$, a function of the data makes $\sum_{i=1}^n (y_i -\hat{y}_i)^2$ as small as possible.)

**Solution:**  

b. Consider the prediction function $\hat{y}_i = b x_i$.  Given a sample $y = \{y_1,y_2,\ldots,y_n\}$ and $x = \{x_1,x_2,\ldots,x_n\}$, show how to use this data to find the value of $b$ that minimizes the prediction error (i.e., what value of $b$, a function of the data makes $\sum_{i=1}^n (y_i -\hat{y}_i)^2$ as small as possible.)

**Solution:**  

